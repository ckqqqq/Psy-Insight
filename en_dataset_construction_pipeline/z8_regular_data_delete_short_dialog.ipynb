{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "\"\"\" json.dumps(): 将 Python 对象编码成 JSON 字符串。 json.dump(): 将 Python 对象编码成 JSON 字符串，并写入到文件中。json.loads(): 将已编码的 JSON 字符串解码为 Python 对象。json.load(): 读取文件中的 JSON 编码的数据，并解码为 Python 对象。\n",
    "    \"\"\"\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "def json_standard(input_object):\n",
    "    return json.dumps(input_object,ensure_ascii=False,indent=4)\n",
    "def read_file(file_path:str):\n",
    "    with open(file_path,\"r\",encoding=\"utf-8\") as i_f:\n",
    "        return json.load(i_f)\n",
    "def write_file(file_path:str,obj,overwrite=False):\n",
    "    if os.path.exists(file_path)==False or overwrite==True:\n",
    "        with open(file_path,\"w\",encoding=\"utf-8\") as o_f:\n",
    "            json.dump(obj,o_f,ensure_ascii=False)\n",
    "        print(f\"写入{file_path}\")\n",
    "    else:\n",
    "        print(f\"{file_path}文件已经存在\")\n",
    "def check_file(file_path:str):\n",
    "    \"\"\"返回该路径下是否存在文件\"\"\"\n",
    "    is_exist=os.path.exists(file_path)\n",
    "    if is_exist:\n",
    "        file_name=file_path.split(\"/\")[-1]\n",
    "        print(f\"{file_name} exist\")\n",
    "    return is_exist\n",
    "import torch\n",
    "import json\n",
    "from transformers import (AutoTokenizer)\n",
    "model_id=\"/home/ckqsudo/code2024/0model/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id)\n",
    "# 这里不设置 trust_remote_code也行\n",
    "tokenizer.padding_size='right'#填充符的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_processed_data=read_file(\"/home/ckqsudo/code2024/Mistral-7b-finetune/data/en_regular_cache4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['theme', 'is_same_qa', 'is_same_case', 'background', 'pre_reasoning', 'topic_dialog', 'post_reasoning'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_processed_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5, 7]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,5]\n",
    "a.extend([7])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_one_participant(cur_dataset):\n",
    "    new_dataset=[]\n",
    "    for topic_dialog in cur_dataset:\n",
    "        participant_set=set()\n",
    "        for dialog_item in topic_dialog[\"topic_dialog\"][\"dialog\"]:\n",
    "            participant_set.add(dialog_item[\"participant\"])\n",
    "        if len(participant_set)==1:\n",
    "            new_dataset[-1][\"topic_dialog\"][\"dialog\"].extend(topic_dialog[\"topic_dialog\"][\"dialog\"])\n",
    "            new_dataset[-1][\"post_reasoning\"]+=topic_dialog[\"pre_reasoning\"]\n",
    "        else:\n",
    "            new_dataset.append(topic_dialog)\n",
    "    return new_dataset\n",
    "def regular_data(cur_data):\n",
    "    for x,item in enumerate(cur_data):\n",
    "        for y,dialog_item in enumerate(item[\"topic_dialog\"][\"dialog\"]):\n",
    "            text=dialog_item[\"text\"]\n",
    "            while text.startswith(\" \"):\n",
    "                text=text[1:]\n",
    "            while text.endswith(\" \"):\n",
    "                text=text[:-1]\n",
    "            cur_data[x][\"topic_dialog\"][\"dialog\"][y][\"text\"]=text\n",
    "\n",
    "def filter_reasoning_observation(cur_data):\n",
    "    for x,topic_dialog in enumerate(cur_data):\n",
    "        for y,dialog_item in enumerate(topic_dialog[\"topic_dialog\"][\"dialog\"]):\n",
    "            if \"Therapist\" in dialog_item[\"participant\"]:\n",
    "                if 'reasoning' not in dialog_item.keys():\n",
    "                    \n",
    "                    cur_data[x][\"topic_dialog\"][\"dialog\"][y]['reasoning']=\"\"\n",
    "            else:\n",
    "                if 'observation' not in dialog_item.keys():\n",
    "                    cur_data[x][\"topic_dialog\"][\"dialog\"][y]['observation']=\"\"\n",
    "    \n",
    "cache_5_dataset=filter_one_participant(en_processed_data)\n",
    "regular_data(cache_5_dataset)\n",
    "filter_reasoning_observation(cache_5_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,topic_dialog in enumerate(cache_5_dataset):\n",
    "    for y,dialog_item in enumerate(topic_dialog[\"topic_dialog\"]['dialog']):\n",
    "        if \"Therapist\" in dialog_item[\"participant\"]:\n",
    "            if 'reasoning' not in dialog_item.keys():\n",
    "                print(dialog_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563, 520)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_processed_data),len(cache_5_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_dialog in cache_5_dataset:\n",
    "    participant_set=set()\n",
    "    for dialog_item in topic_dialog[\"topic_dialog\"][\"dialog\"]:\n",
    "        participant_set.add(dialog_item[\"participant\"])\n",
    "    if len(participant_set)==1:\n",
    "        print(participant_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def regular_data(cur_data): #这个也应该在之前做\n",
    "#     for x,item in enumerate(cur_data):\n",
    "#         for y,dialog_item in enumerate(item[\"topic_dialog\"][\"dialog\"]):\n",
    "#             text=dialog_item[\"text\"]\n",
    "#             while text.startswith(\" \"):\n",
    "#                 text=text[1:]\n",
    "#             while text.endswith(\" \"):\n",
    "#                 text=text[:-1]\n",
    "#             cur_data[x][\"topic_dialog\"][\"dialog\"][y][\"text\"]=text\n",
    "# regular_data(en_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写入en_regular_cache5.json\n"
     ]
    }
   ],
   "source": [
    "write_file(\"en_regular_cache5.json\",cache_5_dataset,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
