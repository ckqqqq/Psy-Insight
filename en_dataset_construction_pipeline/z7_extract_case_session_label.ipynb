{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import torch\n",
                "import os\n",
                "import json\n",
                "\n",
                "torch.cuda.is_available()\n",
                "def json_standard(input_object):\n",
                "    \"\"\"transfrom python object into json and str with json format 从而增强gpt的成功率\n",
                "    json.dumps(): 将 Python 对象编码成 JSON 字符串。\n",
                "    json.dump(): 将 Python 对象编码成 JSON 字符串，并写入到文件中。\n",
                "    json.loads(): 将已编码的 JSON 字符串解码为 Python 对象。\n",
                "    json.load(): 读取文件中的 JSON 编码的数据，并解码为 Python 对象。\n",
                "    \"\"\"\n",
                "    # print(input_object,type(input_object))\n",
                "    return json.dumps(input_object,ensure_ascii=False,indent=4)\n",
                "def read_file(file_path:str):\n",
                "    with open(file_path,\"r\",encoding=\"utf-8\") as i_f:\n",
                "        return json.load(i_f)\n",
                "def write_file(file_path:str,obj,overwrite=False):\n",
                "    if os.path.exists(file_path)==False or overwrite==True:\n",
                "        with open(file_path,\"w\",encoding=\"utf-8\") as o_f:\n",
                "            json.dump(obj,o_f,ensure_ascii=False)\n",
                "        print(f\"写入{file_path}\")\n",
                "    else:\n",
                "        print(f\"{file_path}文件已经存在\")\n",
                "def check_file(file_path:str):\n",
                "    \"\"\"返回该路径下是否存在文件\"\"\"\n",
                "    is_exist=os.path.exists(file_path)\n",
                "    if is_exist:\n",
                "        file_name=file_path.split(\"/\")[-1]\n",
                "        print(f\"{file_name} exist\")\n",
                "    return is_exist\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 计算message 和string中的token数量\n",
                "import tiktoken\n",
                "# 2. Load an encoding 使用tiktoken.get_encoding() 按名称加载编码。第一次运行时，它将需要互联网连接进行下载。后续运行不需要互联网连接。\n",
                "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
                "# 使用tiktoken.encoding_for_model()函数可以自动加载给定模型名称的正确编码。\n",
                "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
                "# 3. Turn text into tokens with encoding.encode() The .encode() method converts a text string into a list of token integers.\n",
                "encoding.encode(\"tiktoken is great!\")\n",
                "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
                "    \"\"\"返回文本字符串中的Token数量\"\"\"\n",
                "    num_tokens=0\n",
                "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
                "    num_tokens = len(encoding.encode(string))\n",
                "    return num_tokens\n",
                "def calculate_messages(messages:list) -> int:\n",
                "    \"\"\"返回总的message长度\"\"\"\n",
                "    counter=0\n",
                "    for mess in messages:\n",
                "        counter+=num_tokens_from_string(mess.content,\"cl100k_base\")\n",
                "    return counter\n",
                "INCONTEXT_WINDOWS_GPT_3_5=16000\n",
                "INCONTEXT_WINDOWS_MOONSHOT=30000\n",
                "from langchain.prompts.chat import (\n",
                "    ChatPromptTemplate,\n",
                "    HumanMessagePromptTemplate,\n",
                "    SystemMessagePromptTemplate,\n",
                ")\n",
                "from langchain.schema import HumanMessage, SystemMessage,AIMessage\n",
                "from langchain_openai import ChatOpenAI\n",
                "import os\n",
                "from langchain.prompts.chat import (\n",
                "    ChatPromptTemplate,\n",
                "    HumanMessagePromptTemplate,\n",
                "    SystemMessagePromptTemplate,\n",
                ")\n",
                "from langchain.schema import HumanMessage, SystemMessage,AIMessage\n",
                "from langchain_openai import ChatOpenAI\n",
                "import time\n",
                "# moonshot_chat.openai_api_base=\"https://api.moonshot.cn/v1\"\n",
                "# moonshot_chat=ChatOpenAI(temperature=0,model=\"moonshot-v1-32k\",openai_api_key='XXX',openai_api_base='https://api.moonshot.cn/v1')\n",
                "# moonshot_chat.temperature\n",
                "class ChatGPTAnnotator:\n",
                "    def __init__(self):\n",
                "        self.chat = ChatOpenAI(temperature=0,\n",
                "                               model=\"gpt-3.5-turbo\",openai_api_key='XXX',\n",
                "                               openai_api_base='https://gptnb.keqichen.top/v1')\n",
                "    def init_judge_samecase_message(self):\n",
                "        fewshot_0_0={\"case a\":\"Therapist: In what way?\\nClient: They think I’m ugly, hideous. I look like the elephant woman. They probably make jokes about me and have a good laugh. I can’t bear it.\\nTherapist: Are those the thoughts that make you so anxious when you go into the high street?\\nClient:  Yes.\\n\",\"case b\":\"Therapist:  One of your underlying assumptions is ‘If I don’t have a real job then I’m not as good as others’. Now you’ve been out of work for several years due to illness and you said you try to cram a lot of activity into each day to prove that you are as good as others by having a job at home, so to speak; so do you see reading the newspaper or watching television as an indulgence, idling when you should be striving?\\nClient: Yes, that’s exactly it now that you’ve mentioned it. It is an indulgence. I should be working hard to make up for not having a real job. I don’t deserve any time to myself. I feel a failure if I don’t complete my daily to-do lists. \\n\"}\n",
                "        fewshot_0_1={\"reasoning\":\"No, case a is about appearance, while case b is related to unemployment. They belong to different counseling topics.\",\"result\":False}\n",
                "        fewshot_1_0={\n",
                "        \"case a\": \"Therapist:That was quite a sigh. How are you feeling at this moment?\\nClient:Down.\\nTherapist:What thoughts are going through your mind right now to make you feel down?\\nClient:I’ve let so many things slip through my fingers. What a waste. Why didn’t I grasp these opportunities and make the most of them?\",\n",
                "        \"case b\": \"Therapist:What’s your answer to your own question?\\nClient:I don’t have the guts to succeed. I’ll never amount to anything important in life. My life is an endless catalogue of missed opportunities.\"\n",
                "        }\n",
                "        fewshot_1_1={\n",
                "        \"reasoning\": \"Both cases is about a topic(missed opportunities) and the dialogues in these two cases are cohesive.\",\n",
                "        \"result\": True\n",
                "        }\n",
                "        messages=[SystemMessage(\n",
                "            content=\"As a helpful AI and a professional psychotherapist. You need to answer question of each User question. Do case a and case b belong to the same counseling topic?. Return True and False. Please return a JSON format response with \\\"reasoning\\\" and \\\"result\\\". \"\n",
                "        ),\n",
                "        HumanMessage(content=json_standard(fewshot_0_0)),\n",
                "        AIMessage(content=json_standard(fewshot_0_1)),\n",
                "        HumanMessage(content=json_standard(fewshot_1_0)),\n",
                "        AIMessage(content=json_standard(fewshot_1_1))\n",
                "        ]\n",
                "        token_count=calculate_messages(messages)\n",
                "        return messages,token_count\n",
                "\n",
                "    def init_judge_qa_message(self):\n",
                "        fewshot_0_0={\"dialog a\":\"Client: I’d have to say “3”.\",\"dialog b\":\"Therapist: So, what are the differences between “0” and “3”?\"}\n",
                "        fewshot_0_1={\"reasoning\":\"These two dialog can form a dialog_pair because they represent an exchange between a client expressing a choice and a therapist seeking clarification\",\"result\":True}\n",
                "        fewshot_1_0={\"dialog a\":\"Client: I will have my things put away and I’ll be standing at my workstation.\",\"dialog b\":\"Therapist: What did you come to see me about?\"}\n",
                "        fewshot_1_1={\"reasoning\":\"They do not form a dialog pair. One is a statement from a client, while the other is a question from a therapist at the beginning of another session. There's no direct response or interaction to constitute a complete dialogue.\",\"result\":False}\n",
                "        fewshot_2_0={\"dialog a\":\"Client: Yes, that’s exactly it now that you’ve mentioned it. It is an indulgence. I should be working hard to make up for not having a real job. I don’t deserve any time to myself. I feel a failure if I don’t complete my daily to-do lists.\",\"dialog b\":\"Therapist: That was quite a sigh. How are you feeling at this moment?\"}\n",
                "        fewshot_2_1={\"reasoning\":\"Client in dialog a expresses guilt over leisure versus work, while Therapist acknowledges client's emotions and inquires about their current state. This continuity shows coherence and emotional connection. And the pronouns like 'that' refer to client's indication: 'It is an indulgence'.\",\"result\":True}\n",
                "        fewshot_3_0={\"dialog a\":\"Client: I’d have to say “3”.\",\"dialog b\":\"Therapist: So, what are the differences between “0” and “3”?\"}\n",
                "        fewshot_3_1={\"reasoning\":\"These two dialog can form a dialog_pair because they represent an exchange between a client expressing a choice and a therapist seeking clarification\",\"result\":True}\n",
                "        messages = [\n",
                "        SystemMessage(\n",
                "            content=\"As a helpful AI and a professional psychotherapist, please help me determine whether dialog a and dialog b can be continue part of a multi-turn dialogue. Return true if they form a responsive dialogue pair, and false if they do not. Please return a JSON format response with \\\"reasoning\\\" and \\\"result\\\". \"\n",
                "        ),\n",
                "\n",
                "        HumanMessage(content=json_standard(fewshot_2_0)),\n",
                "        AIMessage(content=json_standard(fewshot_2_1)),\n",
                "        HumanMessage(content=json_standard(fewshot_0_0)),\n",
                "        AIMessage(content=json_standard(fewshot_0_1)),\n",
                "        HumanMessage(content=json_standard(fewshot_1_0)),\n",
                "        AIMessage(content=json_standard(fewshot_1_1))\n",
                "        ]\n",
                "        token_count=calculate_messages(messages)\n",
                "        return messages,token_count\n",
                "    # def case_judge_message(self):\n",
                "    #     messages\n",
                "    def retry_chat(self,messages,max_try_times:int=3):\n",
                "        response=self.chat(messages)\n",
                "        final_response_content=response.content\n",
                "        counter=0\n",
                "        response_metadata={\"finish_reason\": \"stop\", \"logprobs\": None}\n",
                "        while \"length\" in response.response_metadata[\"finish_reason\"] and counter<max_try_times:\n",
                "            # print(len(messages),response)\n",
                "            messages.append(AIMessage(\n",
                "                content=final_response_content\n",
                "            ))\n",
                "            messages.append(HumanMessage(\n",
                "                content=\"Well done! Please go on.\"\n",
                "            ))\n",
                "            response=self.chat(messages)\n",
                "            final_response_content+=response.content\n",
                "            counter+=1\n",
                "            time.sleep(2)\n",
                "        if counter==max_try_times:\n",
                "            print(response.response_metadata)\n",
                "            raise MyException(\"The response is too long! Max_try!!!!!!!\")\n",
                "        time.sleep(1)\n",
                "        return final_response_content,response.response_metadata\n",
                "    def judge_qa_message(self,input_json:str):\n",
                "        \"\"\"注意，传进来的值一定要经过json标准化\"\"\"\n",
                "        json.loads(input_json)\n",
                "        messages,token_count=self.init_judge_qa_message()\n",
                "        messages.append(HumanMessage(\n",
                "            content=input_json \n",
                "        ))      \n",
                "        resp,meta_data=self.retry_chat(messages,3)\n",
                "        return resp,meta_data\n",
                "    def judge_case_message(self,input_json:str):\n",
                "        messages,token_count=self.init_judge_samecase_message()\n",
                "        messages.append(HumanMessage(\n",
                "            content=input_json \n",
                "        ))\n",
                "        resp,meta_data=self.retry_chat(messages,3)\n",
                "        return resp,meta_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'4dd'"
                        ]
                    },
                    "execution_count": 112,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a=\"1dd\"\n",
                "a.replace(\"1\",\"4\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<module 'json' from '/home/ckqsudo/sys_tool/miniconda/tmp/yes/envs/trl/lib/python3.9/json/__init__.py'>"
                        ]
                    },
                    "execution_count": 113,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a={\"1\":\"2\",\"3\":\"4\"}\n",
                "json.dumps(a)\n",
                "json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {},
            "outputs": [],
            "source": [
                "def a():\n",
                "    return 1,3\n",
                "b,c=a()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from curses import raw\n",
                "\n",
                "\n",
                "def judge_same_case(pre_clip:list,cur_clip:list,is_same_method,chat_item):\n",
                "    if is_same_method==False:\n",
                "        return 0,\"\"\n",
                "    # 这两个是同属一个case吗\n",
                "    input_object={\"case a\":r\"\\n\".join(pre_clip)+r\"\\n\",\"case b\":r\"\\n\".join(cur_clip)+r\"\\n\"}\n",
                "    response,meta_data=chat_item.judge_case_message(json_standard(input_object))\n",
                "    try:\n",
                "        res_j=json.loads(response)\n",
                "        result=1 if res_j[\"result\"] else 0\n",
                "        return result,res_j[\"reasoning\"]\n",
                "    except Exception as e: \n",
                "        print(meta_data,response)\n",
                "        return None,None\n",
                "        time.sleep(4)\n",
                "\n",
                "def judge_qa(pre,cur,is_same_method,is_same_participant,chat_item):\n",
                "    if is_same_method==False or is_same_participant==True:\n",
                "        return 0,\"\"\n",
                "    # 这两个是同属一个QA吗\n",
                "    is_qa=0\n",
                "    input_object={\"dialog a\":pre,\"dialog b\":cur}\n",
                "    response,meta_data=chat_item.judge_qa_message(json_standard(input_object))\n",
                "    try:\n",
                "        res_j=json.loads(response)\n",
                "        result=1 if res_j[\"result\"] else 0\n",
                "        return result,res_j[\"reasoning\"]\n",
                "    except Exception as e: \n",
                "        print(meta_data,res_j)\n",
                "        return None,None\n",
                "\n",
                "        \n",
                "chat_item=ChatGPTAnnotator()\n",
                "def annotate_case(old_topic,cur_topic):\n",
                "    pre_last_4=[item[\"participant\"]+\":\"+item[\"text\"] for item in old_topic[\"topic_dialog\"][\"dialog\"][-4:]]\n",
                "    cur_top_4=[item[\"participant\"]+\":\"+item[\"text\"] for item in cur_topic[\"topic_dialog\"][\"dialog\"][:4]]\n",
                "    is_same_method=old_topic[\"topic_dialog\"][\"method\"]==cur_topic[\"topic_dialog\"][\"method\"]\n",
                "    is_same_participant=old_topic[\"topic_dialog\"][\"dialog\"][-1][\"participant\"]==cur_topic[\"topic_dialog\"][\"dialog\"][0][\"participant\"]\n",
                "    is_same_qa,qa_reasoning=judge_qa(pre_last_4[-1],cur_top_4[0],is_same_method,is_same_participant,chat_item)\n",
                "    is_same_case,case_reason=judge_same_case(pre_last_4,cur_top_4,is_same_method,chat_item)\n",
                "    return is_same_qa,qa_reasoning,is_same_case,case_reason\n",
                "def main():\n",
                "    raw_input_dir=\"/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/修正dialog输出文件夹\"\n",
                "    raw_output_dir=\"/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹\"\n",
                "    file_list=sorted(os.listdir(raw_input_dir),key=lambda x:int(x.split(\"_\")[0]))\n",
                "    for index,file_name in enumerate(file_list[:]):\n",
                "        cur_file_path=raw_input_dir+\"/\"+file_name\n",
                "        output_file_path=raw_output_dir+\"/\"+file_name\n",
                "        if check_file(output_file_path)==False:\n",
                "            cur_json=read_file(cur_file_path)\n",
                "            if index==0:\n",
                "                cur_json[\"is_same_qa\"]=0\n",
                "                cur_json[\"is_same_case\"]=0\n",
                "                write_file(output_file_path,cur_json)\n",
                "            else:#index>0\n",
                "                pre_file_path=raw_input_dir+\"/\"+file_list[index-1]\n",
                "                pre_json=read_file(pre_file_path)\n",
                "                is_same_qa,qa_reasoning,is_same_case,case_reasoning=annotate_case(pre_json,cur_json)\n",
                "                if is_same_qa!=None and is_same_case!=None:\n",
                "                    cur_json[\"is_same_qa\"]=int(is_same_qa)\n",
                "                    cur_json[\"is_same_case\"]=int(is_same_case)\n",
                "                    cur_json[\"extra_info\"]=[qa_reasoning,case_reasoning]\n",
                "                    write_file(output_file_path,cur_json)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 116,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0_cache.json exist\n",
                        "1_cache.json exist\n",
                        "2_cache.json exist\n",
                        "3_cache.json exist\n",
                        "4_cache.json exist\n",
                        "5_cache.json exist\n",
                        "6_cache.json exist\n",
                        "7_cache.json exist\n",
                        "8_cache.json exist\n",
                        "9_cache.json exist\n",
                        "10_cache.json exist\n",
                        "11_cache.json exist\n",
                        "12_cache.json exist\n",
                        "13_cache.json exist\n",
                        "14_cache.json exist\n",
                        "15_cache.json exist\n",
                        "16_cache.json exist\n",
                        "17_cache.json exist\n",
                        "18_cache.json exist\n",
                        "19_cache.json exist\n",
                        "20_cache.json exist\n",
                        "21_cache.json exist\n",
                        "22_cache.json exist\n",
                        "23_cache.json exist\n",
                        "24_cache.json exist\n",
                        "25_cache.json exist\n",
                        "26_cache.json exist\n",
                        "27_cache.json exist\n",
                        "28_cache.json exist\n",
                        "29_cache.json exist\n",
                        "30_cache.json exist\n",
                        "31_cache.json exist\n",
                        "32_cache.json exist\n",
                        "33_cache.json exist\n",
                        "34_cache.json exist\n",
                        "35_cache.json exist\n",
                        "36_cache.json exist\n",
                        "37_cache.json exist\n",
                        "38_cache.json exist\n",
                        "39_cache.json exist\n",
                        "40_cache.json exist\n",
                        "41_cache.json exist\n",
                        "42_cache.json exist\n",
                        "43_cache.json exist\n",
                        "44_cache.json exist\n",
                        "45_cache.json exist\n",
                        "46_cache.json exist\n",
                        "47_cache.json exist\n",
                        "48_cache.json exist\n",
                        "49_cache.json exist\n",
                        "50_cache.json exist\n",
                        "51_cache.json exist\n",
                        "52_cache.json exist\n",
                        "53_cache.json exist\n",
                        "54_cache.json exist\n",
                        "55_cache.json exist\n",
                        "56_cache.json exist\n",
                        "57_cache.json exist\n",
                        "58_cache.json exist\n",
                        "59_cache.json exist\n",
                        "60_cache.json exist\n",
                        "61_cache.json exist\n",
                        "62_cache.json exist\n",
                        "63_cache.json exist\n",
                        "64_cache.json exist\n",
                        "65_cache.json exist\n",
                        "66_cache.json exist\n",
                        "67_cache.json exist\n",
                        "68_cache.json exist\n",
                        "69_cache.json exist\n",
                        "70_cache.json exist\n",
                        "71_cache.json exist\n",
                        "72_cache.json exist\n",
                        "73_cache.json exist\n",
                        "74_cache.json exist\n",
                        "75_cache.json exist\n",
                        "76_cache.json exist\n",
                        "77_cache.json exist\n",
                        "78_cache.json exist\n",
                        "79_cache.json exist\n",
                        "80_cache.json exist\n",
                        "81_cache.json exist\n",
                        "82_cache.json exist\n",
                        "83_cache.json exist\n",
                        "84_cache.json exist\n",
                        "85_cache.json exist\n",
                        "86_cache.json exist\n",
                        "87_cache.json exist\n",
                        "88_cache.json exist\n",
                        "89_cache.json exist\n",
                        "90_cache.json exist\n",
                        "91_cache.json exist\n",
                        "92_cache.json exist\n",
                        "93_cache.json exist\n",
                        "94_cache.json exist\n",
                        "95_cache.json exist\n",
                        "96_cache.json exist\n",
                        "97_cache.json exist\n",
                        "98_cache.json exist\n",
                        "99_cache.json exist\n",
                        "100_cache.json exist\n",
                        "101_cache.json exist\n",
                        "102_cache.json exist\n",
                        "103_cache.json exist\n",
                        "104_cache.json exist\n",
                        "105_cache.json exist\n",
                        "106_cache.json exist\n",
                        "107_cache.json exist\n",
                        "108_cache.json exist\n",
                        "109_cache.json exist\n",
                        "110_cache.json exist\n",
                        "111_cache.json exist\n",
                        "112_cache.json exist\n",
                        "113_cache.json exist\n",
                        "114_cache.json exist\n",
                        "115_cache.json exist\n",
                        "116_cache.json exist\n",
                        "117_cache.json exist\n",
                        "118_cache.json exist\n",
                        "119_cache.json exist\n",
                        "120_cache.json exist\n",
                        "121_cache.json exist\n",
                        "122_cache.json exist\n",
                        "123_cache.json exist\n",
                        "124_cache.json exist\n",
                        "125_cache.json exist\n",
                        "126_cache.json exist\n",
                        "127_cache.json exist\n",
                        "128_cache.json exist\n",
                        "129_cache.json exist\n",
                        "130_cache.json exist\n",
                        "131_cache.json exist\n",
                        "132_cache.json exist\n",
                        "133_cache.json exist\n",
                        "134_cache.json exist\n",
                        "135_cache.json exist\n",
                        "136_cache.json exist\n",
                        "137_cache.json exist\n",
                        "138_cache.json exist\n",
                        "139_cache.json exist\n",
                        "140_cache.json exist\n",
                        "141_cache.json exist\n",
                        "142_cache.json exist\n",
                        "143_cache.json exist\n",
                        "144_cache.json exist\n",
                        "145_cache.json exist\n",
                        "146_cache.json exist\n",
                        "147_cache.json exist\n",
                        "148_cache.json exist\n",
                        "149_cache.json exist\n",
                        "150_cache.json exist\n",
                        "151_cache.json exist\n",
                        "152_cache.json exist\n",
                        "153_cache.json exist\n",
                        "154_cache.json exist\n",
                        "155_cache.json exist\n",
                        "156_cache.json exist\n",
                        "157_cache.json exist\n",
                        "158_cache.json exist\n",
                        "159_cache.json exist\n",
                        "160_cache.json exist\n",
                        "161_cache.json exist\n",
                        "162_cache.json exist\n",
                        "163_cache.json exist\n",
                        "164_cache.json exist\n",
                        "165_cache.json exist\n",
                        "166_cache.json exist\n",
                        "167_cache.json exist\n",
                        "168_cache.json exist\n",
                        "169_cache.json exist\n",
                        "170_cache.json exist\n",
                        "171_cache.json exist\n",
                        "172_cache.json exist\n",
                        "173_cache.json exist\n",
                        "174_cache.json exist\n",
                        "175_cache.json exist\n",
                        "176_cache.json exist\n",
                        "177_cache.json exist\n",
                        "178_cache.json exist\n",
                        "179_cache.json exist\n",
                        "180_cache.json exist\n",
                        "181_cache.json exist\n",
                        "182_cache.json exist\n",
                        "183_cache.json exist\n",
                        "184_cache.json exist\n",
                        "185_cache.json exist\n",
                        "186_cache.json exist\n",
                        "187_cache.json exist\n",
                        "188_cache.json exist\n",
                        "189_cache.json exist\n",
                        "190_cache.json exist\n",
                        "191_cache.json exist\n",
                        "192_cache.json exist\n",
                        "193_cache.json exist\n",
                        "194_cache.json exist\n",
                        "195_cache.json exist\n",
                        "196_cache.json exist\n",
                        "197_cache.json exist\n",
                        "198_cache.json exist\n",
                        "199_cache.json exist\n",
                        "200_cache.json exist\n",
                        "201_cache.json exist\n",
                        "202_cache.json exist\n",
                        "203_cache.json exist\n",
                        "204_cache.json exist\n",
                        "205_cache.json exist\n",
                        "206_cache.json exist\n",
                        "207_cache.json exist\n",
                        "208_cache.json exist\n",
                        "209_cache.json exist\n",
                        "210_cache.json exist\n",
                        "211_cache.json exist\n",
                        "212_cache.json exist\n",
                        "213_cache.json exist\n",
                        "214_cache.json exist\n",
                        "215_cache.json exist\n",
                        "216_cache.json exist\n",
                        "217_cache.json exist\n",
                        "218_cache.json exist\n",
                        "219_cache.json exist\n",
                        "220_cache.json exist\n",
                        "221_cache.json exist\n",
                        "222_cache.json exist\n",
                        "223_cache.json exist\n",
                        "224_cache.json exist\n",
                        "225_cache.json exist\n",
                        "226_cache.json exist\n",
                        "227_cache.json exist\n",
                        "228_cache.json exist\n",
                        "229_cache.json exist\n",
                        "230_cache.json exist\n",
                        "231_cache.json exist\n",
                        "232_cache.json exist\n",
                        "233_cache.json exist\n",
                        "234_cache.json exist\n",
                        "235_cache.json exist\n",
                        "236_cache.json exist\n",
                        "237_cache.json exist\n",
                        "238_cache.json exist\n",
                        "239_cache.json exist\n",
                        "240_cache.json exist\n",
                        "241_cache.json exist\n",
                        "242_cache.json exist\n",
                        "243_cache.json exist\n",
                        "244_cache.json exist\n",
                        "245_cache.json exist\n",
                        "246_cache.json exist\n",
                        "247_cache.json exist\n",
                        "248_cache.json exist\n",
                        "249_cache.json exist\n",
                        "250_cache.json exist\n",
                        "251_cache.json exist\n",
                        "252_cache.json exist\n",
                        "253_cache.json exist\n",
                        "254_cache.json exist\n",
                        "255_cache.json exist\n",
                        "256_cache.json exist\n",
                        "257_cache.json exist\n",
                        "258_cache.json exist\n",
                        "259_cache.json exist\n",
                        "260_cache.json exist\n",
                        "261_cache.json exist\n",
                        "262_cache.json exist\n",
                        "263_cache.json exist\n",
                        "264_cache.json exist\n",
                        "265_cache.json exist\n",
                        "266_cache.json exist\n",
                        "267_cache.json exist\n",
                        "268_cache.json exist\n",
                        "269_cache.json exist\n",
                        "270_cache.json exist\n",
                        "271_cache.json exist\n",
                        "272_cache.json exist\n",
                        "273_cache.json exist\n",
                        "274_cache.json exist\n",
                        "275_cache.json exist\n",
                        "276_cache.json exist\n",
                        "277_cache.json exist\n",
                        "278_cache.json exist\n",
                        "279_cache.json exist\n",
                        "280_cache.json exist\n",
                        "281_cache.json exist\n",
                        "282_cache.json exist\n",
                        "283_cache.json exist\n",
                        "284_cache.json exist\n",
                        "285_cache.json exist\n",
                        "286_cache.json exist\n",
                        "287_cache.json exist\n",
                        "288_cache.json exist\n",
                        "289_cache.json exist\n",
                        "290_cache.json exist\n",
                        "291_cache.json exist\n",
                        "292_cache.json exist\n",
                        "293_cache.json exist\n",
                        "294_cache.json exist\n",
                        "295_cache.json exist\n",
                        "296_cache.json exist\n",
                        "297_cache.json exist\n",
                        "298_cache.json exist\n",
                        "299_cache.json exist\n",
                        "300_cache.json exist\n",
                        "301_cache.json exist\n",
                        "302_cache.json exist\n",
                        "303_cache.json exist\n",
                        "304_cache.json exist\n",
                        "305_cache.json exist\n",
                        "306_cache.json exist\n",
                        "307_cache.json exist\n",
                        "308_cache.json exist\n",
                        "309_cache.json exist\n",
                        "310_cache.json exist\n",
                        "311_cache.json exist\n",
                        "312_cache.json exist\n",
                        "313_cache.json exist\n",
                        "314_cache.json exist\n",
                        "315_cache.json exist\n",
                        "316_cache.json exist\n",
                        "317_cache.json exist\n",
                        "318_cache.json exist\n",
                        "319_cache.json exist\n",
                        "320_cache.json exist\n",
                        "321_cache.json exist\n",
                        "322_cache.json exist\n",
                        "323_cache.json exist\n",
                        "324_cache.json exist\n",
                        "325_cache.json exist\n",
                        "326_cache.json exist\n",
                        "327_cache.json exist\n",
                        "328_cache.json exist\n",
                        "329_cache.json exist\n",
                        "330_cache.json exist\n",
                        "331_cache.json exist\n",
                        "332_cache.json exist\n",
                        "333_cache.json exist\n",
                        "334_cache.json exist\n",
                        "335_cache.json exist\n",
                        "336_cache.json exist\n",
                        "337_cache.json exist\n",
                        "338_cache.json exist\n",
                        "339_cache.json exist\n",
                        "340_cache.json exist\n",
                        "341_cache.json exist\n",
                        "342_cache.json exist\n",
                        "343_cache.json exist\n",
                        "344_cache.json exist\n",
                        "345_cache.json exist\n",
                        "346_cache.json exist\n",
                        "347_cache.json exist\n",
                        "348_cache.json exist\n",
                        "349_cache.json exist\n",
                        "350_cache.json exist\n",
                        "351_cache.json exist\n",
                        "352_cache.json exist\n",
                        "353_cache.json exist\n",
                        "354_cache.json exist\n",
                        "355_cache.json exist\n",
                        "356_cache.json exist\n",
                        "357_cache.json exist\n",
                        "358_cache.json exist\n",
                        "359_cache.json exist\n",
                        "360_cache.json exist\n",
                        "361_cache.json exist\n",
                        "362_cache.json exist\n",
                        "363_cache.json exist\n",
                        "364_cache.json exist\n",
                        "365_cache.json exist\n",
                        "366_cache.json exist\n",
                        "367_cache.json exist\n",
                        "368_cache.json exist\n",
                        "369_cache.json exist\n",
                        "370_cache.json exist\n",
                        "371_cache.json exist\n",
                        "372_cache.json exist\n",
                        "373_cache.json exist\n",
                        "374_cache.json exist\n",
                        "375_cache.json exist\n",
                        "376_cache.json exist\n",
                        "377_cache.json exist\n",
                        "378_cache.json exist\n",
                        "379_cache.json exist\n",
                        "380_cache.json exist\n",
                        "381_cache.json exist\n",
                        "382_cache.json exist\n",
                        "383_cache.json exist\n",
                        "384_cache.json exist\n",
                        "385_cache.json exist\n",
                        "386_cache.json exist\n",
                        "387_cache.json exist\n",
                        "388_cache.json exist\n",
                        "389_cache.json exist\n",
                        "390_cache.json exist\n",
                        "391_cache.json exist\n",
                        "392_cache.json exist\n",
                        "393_cache.json exist\n",
                        "394_cache.json exist\n",
                        "395_cache.json exist\n",
                        "396_cache.json exist\n",
                        "397_cache.json exist\n",
                        "398_cache.json exist\n",
                        "399_cache.json exist\n",
                        "400_cache.json exist\n",
                        "401_cache.json exist\n",
                        "402_cache.json exist\n",
                        "403_cache.json exist\n",
                        "404_cache.json exist\n",
                        "405_cache.json exist\n",
                        "406_cache.json exist\n",
                        "407_cache.json exist\n",
                        "408_cache.json exist\n",
                        "409_cache.json exist\n",
                        "410_cache.json exist\n",
                        "411_cache.json exist\n",
                        "412_cache.json exist\n",
                        "413_cache.json exist\n",
                        "414_cache.json exist\n",
                        "415_cache.json exist\n",
                        "416_cache.json exist\n",
                        "417_cache.json exist\n",
                        "418_cache.json exist\n",
                        "419_cache.json exist\n",
                        "420_cache.json exist\n",
                        "421_cache.json exist\n",
                        "422_cache.json exist\n",
                        "423_cache.json exist\n",
                        "424_cache.json exist\n",
                        "425_cache.json exist\n",
                        "426_cache.json exist\n",
                        "427_cache.json exist\n",
                        "428_cache.json exist\n",
                        "429_cache.json exist\n",
                        "430_cache.json exist\n",
                        "431_cache.json exist\n",
                        "432_cache.json exist\n",
                        "433_cache.json exist\n",
                        "434_cache.json exist\n",
                        "435_cache.json exist\n",
                        "436_cache.json exist\n",
                        "437_cache.json exist\n",
                        "438_cache.json exist\n",
                        "439_cache.json exist\n",
                        "440_cache.json exist\n",
                        "441_cache.json exist\n",
                        "442_cache.json exist\n",
                        "443_cache.json exist\n",
                        "444_cache.json exist\n",
                        "445_cache.json exist\n",
                        "446_cache.json exist\n",
                        "447_cache.json exist\n",
                        "448_cache.json exist\n",
                        "449_cache.json exist\n",
                        "450_cache.json exist\n",
                        "451_cache.json exist\n",
                        "452_cache.json exist\n",
                        "453_cache.json exist\n",
                        "454_cache.json exist\n",
                        "455_cache.json exist\n",
                        "456_cache.json exist\n",
                        "457_cache.json exist\n",
                        "458_cache.json exist\n",
                        "459_cache.json exist\n",
                        "460_cache.json exist\n",
                        "461_cache.json exist\n",
                        "462_cache.json exist\n",
                        "463_cache.json exist\n",
                        "464_cache.json exist\n",
                        "465_cache.json exist\n",
                        "466_cache.json exist\n",
                        "467_cache.json exist\n",
                        "468_cache.json exist\n",
                        "469_cache.json exist\n",
                        "470_cache.json exist\n",
                        "471_cache.json exist\n",
                        "472_cache.json exist\n",
                        "473_cache.json exist\n",
                        "474_cache.json exist\n",
                        "475_cache.json exist\n",
                        "476_cache.json exist\n",
                        "477_cache.json exist\n",
                        "478_cache.json exist\n",
                        "479_cache.json exist\n",
                        "480_cache.json exist\n",
                        "481_cache.json exist\n",
                        "482_cache.json exist\n",
                        "483_cache.json exist\n",
                        "484_cache.json exist\n",
                        "485_cache.json exist\n",
                        "486_cache.json exist\n",
                        "487_cache.json exist\n",
                        "488_cache.json exist\n",
                        "489_cache.json exist\n",
                        "490_cache.json exist\n",
                        "491_cache.json exist\n",
                        "492_cache.json exist\n",
                        "493_cache.json exist\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/494_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/495_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/496_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/497_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/498_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/499_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/500_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/501_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/502_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/503_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/504_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/505_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/506_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/507_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/508_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/509_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/510_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/511_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/512_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/513_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/514_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/515_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/516_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/517_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/518_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/519_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/520_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/521_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/522_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/523_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/524_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/525_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/526_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/527_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/528_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/529_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/530_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/531_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/532_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/533_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/534_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/535_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/536_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/537_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/538_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/539_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/540_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/541_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/542_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/543_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/544_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/545_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/546_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/547_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/548_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/549_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/550_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/551_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/552_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/553_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/554_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/555_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/556_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/557_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/558_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/559_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/560_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/561_cache.json\n",
                        "写入/home/ckqsudo/code2024/0dataset/E-bed/English/z3_gpt_mapping.ipynb/添加标记case文件夹/562_cache.json\n"
                    ]
                }
            ],
            "source": [
                "main()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "     "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "trl",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
