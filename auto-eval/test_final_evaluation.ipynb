{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import result\n",
    "import nltk\n",
    "import jieba\n",
    "class Bleu():\n",
    "    def __init__(self):\n",
    "        self.model = nltk.translate.bleu_score.sentence_bleu\n",
    "        self.smoothing_func = nltk.translate.bleu_score.SmoothingFunction().method1\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"bleu-\"\n",
    "    def calc(self, hyps, ref, ngram_list) -> float:\n",
    "        ref = ' '.join(jieba.cut(ref))\n",
    "        hyps = ' '.join(jieba.cut(hyps))\n",
    "        # 获取 n 的值\n",
    "        result={}\n",
    "        for ngram in ngram_list:\n",
    "            n = ngram  # 如果没有传递 n，则使用默认的 ngram\n",
    "            weights = [1 / n] * n  # 根据传入的 n 计算权重\n",
    "            print(self.name)\n",
    "            ref_list=[ref.split()]\n",
    "            blue_n = self.model(ref_list, hyps.split(), weights=weights, smoothing_function=self.smoothing_func)\n",
    "            result['blue-'+str(n):blue_n]\n",
    "        return blue_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "predictions = [\"It is a guide to action which ensures that the military always obeys the commands of the party.\"]\n",
    "\n",
    "references = [\"It is a guide to action that ensures that the military will forever heed Party commands.\"]\n",
    "\n",
    "class Rouge():\n",
    "    def __init__(self):\n",
    "        self.rouge = evaluate.load('rouge')\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"Rouge\"\n",
    "    def calc(self, hyps, ref, ngram_list) -> float:\n",
    "        results = self.rouge.compute(predictions=predictions, references=references)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/ckqsudo/.cache/huggingface/modules/evaluate_modules/metrics/lsy641--distinct/37630ba4ab189baf7810235851bada3c179378a032d34fd95a3d5e83ac68ef2d (last modified on Tue Jun 11 19:09:13 2024) since it couldn't be found locally at lsy641--distinct, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "mistral_tokenizer = AutoTokenizer.from_pretrained(\"/home/ckqsudo/code2024/0model/Mistral-7B-Instruct-v0.2\",padding=\"longest\")\n",
    "class Distinct():\n",
    "    def __init__(self):\n",
    "        # 加载Distinct模型\n",
    "        self.distinct = evaluate.load(\"lsy641/distinct\")\n",
    "    def calc(self,hyps_sentence_list,tokenizer=None):\n",
    "        if tokenizer!=None:\n",
    "            results1 = self.distinct.compute(predictions=hyps_sentence_list, vocab_size=50257)\n",
    "distinct_n=Distinct()\n",
    "predictions = [\"It is a guide to action which ensures that the military always obeys the commands of the party.\"]\n",
    "\n",
    "references = [\"It is a guide to action that ensures that the military will forever heed Party commands.\"]\n",
    "\n",
    "dataset = [\"This is my friend jack\", \"I'm sorry to hear that\", \"But you know I am the one who always support you\", \"Welcome to our family\",\"Hi.\", \"I am sorry to hear that\", \"I don't know\", \"Do you know who that person is?\"]\n",
    "distinct_n.calc(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
